  1 syntax enable " Enable syntax highlighting  2 filetype indent on  3  4 " Adjust tab spacing defaults  5 " -----------------------------------------------------------  6 set tabstop=4       " Number of spaces/tab char  7 set softtabstop=4   " Number of spaces in a tab when editing  8 set expandtab       " Tabs are just 4 spaces  9 " ----------------------------------------------------------- 10 11 " UI configuration stuff 12 " ----------------------------------------------------------- 13 set number          " line numbers 14 set showcmd         " Show command line in the bottom bar 15 set cursorline      " highlight the current line 16 filetype indent on   " Load file specific indent files 17 set wildmenu        " A sort of autocomplete for the command menu, provides a list of possible matches ~ tab complete 18 set showmatch       " Shows the matching parens ~ brackets, etc. 19 20 " Searching 21 " ----------------------------------------------------------- 22 set incsearch       " Search as characters are being entered 23 set hlsearch        " Highlight matches 24 25 " Folding 26 " ----------------------------------------------------------- 27 set foldenable          " Enabled folding 28 set foldlevelstart=10   " Open most folds by default 29 set foldnestmax=10      " max is 10 nested folds 30 set foldmethod=indent   " fold based on indents,V
https://jira.mmodal.com/browse/SPEECHC-6417,v
nohup /opt/mmodal/cds/CdsDist/bin/jCds.sh /workspace/scm/corespeech/scripts/alignLabelsAndCtmQueue.py -since 45 -oidlike 2.16.840.1.113883.3.21.17302.6033335.603925.6033299700 &> rfctOutput.log &,v
    # TODO: Troubleshoot the annotation worker to ensure the truncate functionality is working.,V
from utils.argutils import printArgs, getOids,v
import plotly ,V
"""========Barchart========A bar plot with errorbars and height labels on individual bars"""import numpy as npimport matplotlib.pyplot as pltN = 5men_means = (20, 35, 30, 35, 27)men_std = (2, 3, 4, 1, 2)ind = np.arange(N)  # the x locations for the groupswidth = 0.35       # the width of the barsfig, ax = plt.subplots()rects1 = ax.bar(ind, men_means, width, color='r', yerr=men_std)women_means = (25, 32, 34, 20, 25)women_std = (3, 5, 2, 3, 3)rects2 = ax.bar(ind + width, women_means, width, color='y', yerr=women_std)# add some text for labels, title and axes ticksax.set_ylabel('Scores')ax.set_title('Scores by group and gender')ax.set_xticks(ind + width / 2)ax.set_xticklabels(('G1', 'G2', 'G3', 'G4', 'G5'))ax.legend((rects1[0], rects2[0]), ('Men', 'Women'))def autolabel(rects):    """    Attach a text label above each bar displaying its height    """    for rect in rects:        height = rect.get_height()        ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,                '%d' % int(height),                ha='center', va='bottom')autolabel(rects1)autolabel(rects2)plt.show(),v
13ISDXcmBXpJSe86bDoP,v
import plotly,V
u'https://plot.ly/~PythonPlotBot/27',v
plotly.tools.set_credentials_file(username='paul.hahn', api_key='13ISDXcmBXpJSe86bDoP'),V
OpaqueWhenFocused=no,V
a[e["recognition_index"] - 1],v
Transparency=low,V
BoldAsFont=-1,V
BoldWhite=255,255,255,V
White=205,205,205,V
BoldCyan=179,210,229,V
Cyan=96,161,201,V
BoldMagenta=229,179,210,V
Magenta=201,96,161,V
BoldBlue=198,179,229,V
Blue=136,96,201,V
BoldYellow=210,229,179,V
Yellow=161,201,96,V
BoldGreen=179,229,198,V
Green=96,201,136,V
BoldRed=229,198,179,V
Red=201,136,96,V
BoldBlack=53,53,53,V
Black=0,0,0,V
CursorColour=255,255,255,V
ForegroundColour=0,255,0,V
BackgroundColour=0,0,0,V
ForegroundColour = 131, 148, 150BackgroundColour =   0,   0,   0CursorColour     = 220,  50,  47Black            =   7,  54,  66BoldBlack        =   0,  43,  54Red              = 220,  50,  47BoldRed          = 203,  75,  22Green            =   0, 200, 132BoldGreen        =   0, 200, 132Yellow           = 204, 204, 102BoldYellow       = 204, 204, 102Blue             = 102, 153, 204BoldBlue         = 102, 153, 204Magenta          = 211,  54, 130BoldMagenta      = 108, 113, 196Cyan             =  42, 161, 152BoldCyan         = 147, 161, 161White            = 238, 232, 213BoldWhite        = 253, 246, 227,v
,1
base16-spacemacs,v
remote: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).,v
abort: no suitable response from remote hg!,v
2.16.840.1.113883.3.21.11160.28057.29026.22697036/A~Author,v
        ,V
/cds/cds2/bin/jCds.sh /fs3/tmp/curt.young/scripts/labelSessionLogs.py -oidList label_logs.lst,v
grep "extracted" out.log | sort | uniq -c | sort -rn                                                                                                           123 Suspect token extracted from context: the, Full Diff: ['the', 'dictate', 'gross']       vs.     ['dictate', 'gross']    104 Suspect token extracted from context: five, Full Diff: ['five', 'dictate', 'gross']     vs.     ['dictate', 'gross']     58 Suspect token extracted from context: , Full Diff: ['dictate', 'dictate', 'gross']      vs.     ['dictate', 'gross']     33 Suspect token extracted from context: 5, Full Diff: ['5', 'dictate', 'gross']   vs.     ['dictate', 'gross']     30 Suspect token extracted from context: with, Full Diff: ['with', 'dictate', 'gross']     vs.     ['dictate', 'gross']     19 Suspect token extracted from context: six, Full Diff: ['six', 'dictate', 'gross']       vs.     ['dictate', 'gross']     19 Suspect token extracted from context: a, Full Diff: ['a', 'dictate', 'gross']   vs.     ['dictate', 'gross']     10 Suspect token extracted from context: is, Full Diff: ['is', 'dictate', 'gross'] vs.     ['dictate', 'gross']      7 Suspect token extracted from context: , Full Diff: ['gross', 'dictate', 'gross']        vs.     ['dictate', 'gross']      6 Suspect token extracted from context: the, Full Diff: ['the', 'dictate', 'Gross']       vs.     ['dictate', 'Gross']      6 Suspect token extracted from context: gross, Full Diff: ['Gross', 'dictate', 'gross']   vs.     ['dictate', 'Gross']      6 Suspect token extracted from context: 6, Full Diff: ['6', 'dictate', 'gross']   vs.     ['dictate', 'gross']      5 Suspect token extracted from context: Booth, Full Diff: ['Booth', 'dictate', 'gross']   vs.     ['dictate', 'gross']      3 Suspect token extracted from context: bill, Full Diff: ['bill', 'dictate', 'gross']     vs.     ['dictate', 'gross']      3 Suspect token extracted from context: Hatch, Full Diff: ['Hatch', 'dictate', 'Gross']   vs.     ['dictate', 'Gross']      2 Suspect token extracted from context: of, Full Diff: ['of', 'dictate', 'gross'] vs.     ['dictate', 'gross']      2 Suspect token extracted from context: hatch, Full Diff: ['hatch', 'dictate', 'gross']   vs.     ['dictate', 'gross']      2 Suspect token extracted from context: five, Full Diff: ['five', 'dictate', 'Gross']     vs.     ['dictate', 'Gross']      2 Suspect token extracted from context: Quinn, Full Diff: ['Quinn', 'dictate', 'gross']   vs.     ['dictate', 'gross']      2 Suspect token extracted from context: Hatch, Full Diff: ['Hatch', 'dictate', 'gross']   vs.     ['dictate', 'gross']      2 Suspect token extracted from context: Gross, Full Diff: ['Gross', 'dictate', 'gross']   vs.     ['dictate', 'gross']      2 Suspect token extracted from context: "dictate, Full Diff: ['"dictate', 'dictate', 'gross']     vs.     ['dictate', 'gross']      2 Suspect token extracted from context: ", Full Diff: ['"', 'dictate', 'gross']   vs.     ['dictate', 'gross']      1 Suspect token extracted from context: yellow, Full Diff: ['yellow', 'dictate', 'gross'] vs.     ['dictate', 'gross']      1 Suspect token extracted from context: ulcer, Full Diff: ['ulcer', 'dictate', 'gross']   vs.     ['dictate', 'gross']      1 Suspect token extracted from context: thick, Full Diff: ['thick', 'dictate', 'gross']   vs.     ['dictate', 'gross']      1 Suspect token extracted from context: th, Full Diff: ['th', 'dictate', 'gross'] vs.     ['dictate', 'gross']      1 Suspect token extracted from context: shorter, Full Diff: ['shorter', 'dictate', 'Gross']       vs.     ['dictate', 'Gross']      1 Suspect token extracted from context: sampled, Full Diff: ['sampled', 'dictate', 'Gross']       vs.     ['dictate', 'Gross']      1 Suspect token extracted from context: intro, Full Diff: ['intro', 'dictate', 'Gross']   vs.     ['dictate', 'Gross']      1 Suspect token extracted from context: head, Full Diff: ['head', 'dictate', 'gross']     vs.     ['dictate', 'gross']      1 Suspect token extracted from context: hatch, Full Diff: ['hatch', 'dictate', 'Gross']   vs.     ['dictate', 'Gross']      1 Suspect token extracted from context: good, Full Diff: ['good', 'dictate', 'gross']     vs.     ['dictate', 'gross']      1 Suspect token extracted from context: goo, Full Diff: ['goo', 'dictate', 'gross']       vs.     ['dictate', 'gross']      1 Suspect token extracted from context: date, Full Diff: ['date', 'dictate', 'gross']     vs.     ['dictate', 'gross']      1 Suspect token extracted from context: booth, Full Diff: ['booth', 'dictate', 'gross']   vs.     ['dictate', 'gross']      1 Suspect token extracted from context: bill, Full Diff: ['bill', 'dictate', 'Gross']     vs.     ['dictate', 'Gross']      1 Suspect token extracted from context: and, Full Diff: ['and', 'dictate', 'gross']       vs.     ['dictate', 'gross']      1 Suspect token extracted from context: Walsh, Full Diff: ['Walsh', 'dictate', 'Gross']   vs.     ['dictate', 'Gross']      1 Suspect token extracted from context: K, Full Diff: ['K', 'dictate', 'gross']   vs.     ['dictate', 'gross']      1 Suspect token extracted from context: Davis, Full Diff: ['Davis', 'dictate', 'Gross']   vs.     ['dictate', 'Gross']      1 Suspect token extracted from context: COO, Full Diff: ['COO', 'dictate', 'gross']       vs.     ['dictate', 'gross']      1 Suspect token extracted from context: A, Full Diff: ['A', 'dictate', 'gross']   vs.     ['dictate', 'gross']      1 Suspect token extracted from context: 5th, Full Diff: ['5th', 'dictate', 'gross']       vs.     ['dictate', 'gross']      1 Suspect token extracted from context: 311, Full Diff: ['311', 'dictate', 'gross']       vs.     ['dictate', 'gross']      1 Suspect token extracted from context: 311, Full Diff: ['311', 'dictate', 'Gross']       vs.     ['dictate', 'Gross']      1 Suspect token extracted from context: 2, Full Diff: ['2', 'dictate', 'gross']   vs.     ['dictate', 'gross'],v
autocmd FileType python setlocal expandtab tabstop=4 softtabstop=4 shiftwidth=4,v
{code}//Get INCOMPLETEsnohup /opt/mmodal/cds/CdsDist/bin/jCds.sh /workspace/paul/corespeech/scripts/getIslDataV3.py -Mi 2.16.840.1.113883.3.21.1129.6033091.6032514378/9~Author -s "10 days" -f ".+" 'INCOMPLETE' -o cterm.csv &> teeput.log &//Get Long phonesnohup /opt/mmodal/cds/CdsDist/bin/jCds.sh /workspace/scm/corespeech/scripts/getIslDataV3.py -Mi 2.16.840.1.113883.3.21.1129.6033091.6032514378/9~Author --fpath /workspace/scm/corespeech/scripts/dotlabels.py labelfunc .+ .+ 90  -o long_phones.csv -s "200 days" &> teeput2.log &//Get population swet to collect statsnohup /opt/mmodal/cds/CdsDist/bin/jCds.sh /workspace/paul/corespeech/scripts/getIslDataV3.py -Mi 2.16.840.1.113883.3.21.1129.6033091.6032514378/9~Author -s "10 days" -o all.csv &> teeput3.log &//Get low confidence insertions of words found in INCOMPLETE resultsnohup /opt/mmodal/cds/CdsDist/bin/jCds.sh /workspace/paul/corespeech/scripts/getIslDataV3.py -Mi 2.16.840.1.113883.3.21.1129.6033091.6032514378/9~Author -s "10 days" --contextConfidenceRegex "(?i)\S+ (the|no|all|set|cap|caps|add|top|click) \S+" "0.0" "0.6" ".+" -o conf.csv &> teeput.log &{code}*Results*{noformat}cut -d, -f25 cterm.csv | sort | uniq -c | sort -rn      8 the INCOMPLETE      2 no INCOMPLETE      1 top INCOMPLETE      1 cut INCOMPLETE      1 click INCOMPLETEcut -d, -f25 long_phones.csv | cut -d' ' -f1 | sort | uniq -c | sort -rn     46 the     12 in     10 he      7 her      3 on      2 see      2 no      2 how      1 with      1 she      1 out      1 it      1 if      1 at      1 an      1 _D      1 _B      1column -s, -t isolated.csvComponent Name                                                            Rate/ISL             Standard Score       Count  Population Count2.16.840.1.113883.3.21.1129.6033091.6032514378/A~UserProfile.60388205863  0.3605015673981191   0.9999999999999999   115    3192.16.840.1.113883.3.21.1129.6033091.6032514378/A~UserProfile.60389003542  0.11764705882352941  -1.0000000000000002  10     85                                                                                               Standard Deviation: 0.121427254287{noformat}Profiles seem to continue to do okay. I have requested some more detailed information on SPEECHOPS-2230. The "the" INS + SUB rates for each transcribed profile will give me an idea whether I should lock a profile or allow this author to continue training.,v
/opt/mmodal/cds/CdsDist/bin/jCds.sh /workspace/curt.young/scripts/copyUserProfile.py -profileoid 2.16.840.1.113883.3.21.1129.603196.603815901/A~UserProfile.60388625205 -targetauthor 2.16.840.1.113883.3.21.1129.603196.603815901/9~Author -targetchannel '11025-hq' -targetversionstatus 6,V
ssh://r1+Michael.antonacci@polamalu.interactivesys.com//opt/hgs/corespeech,v
ssh://r1+paul.hahn@polamalu//opt/hgs/corespeech,v
,V
hg clone ssh://r1+paul.hahn@polamalu//opt/hgs/corespeech,V
"""    commandEvaluation.py    Created by Paul Hahn    08/28/17    Troubleshoot timeout causation in general and specific use cases."""# Environment imports# CDS and environment importsfrom base.env import Envfrom com.mmodal.cds import Environment, ObjectId, ObjectIdToolsfrom com.mmodal.cds.util import InternalObjectIdToolsfrom com.mmodal.cds.service.vocab import CodedValueTools# Utilitiesfrom utils.argutils import printArgs, getOidsfrom java.util import Date# Generalimport argparseimport refrom java.util import Calendarfrom java.text import SimpleDateFormat# Field typesfrom com.mmodal.cds.interactive import DictationFieldfrom com.mmodal.cds.interactive import GrammarFieldfrom com.mmodal.cds.interactive import TextSelectionFieldclass ReverseCommandArbiter(object):    """        A class to hold all of the functions specific to reverse engineering the command arbitration    """    def __init__(self):        # Blocks are what I am calling the recognition sequences ~ decoding loops        self.isls = []    def get_recognition_blocks(self, isl_str, cr):        """        A function to extract the field type, token, and timing metrics of an ISL and add it to our collection        :param isl_obj: ISL object        :return: recognition blocks related to this ISL        """        recognition_blocks = []        # Get Interactive Session Log and author specs        isl_svc = Env.get_service("InteractiveSessionLog", isl_str)        isl_obj = isl_svc.getSessionLog(isl_str)        author_oid_obj = ObjectIdTools.construct(isl_obj.getSpeakerId())        # Get call logs        print("Collecting recognition result alternatives..")        for call_log in isl_obj.getCallLogs():            if call_log and call_log.getResult():                for result in call_log.getResult().getResults():                    result_id = result.getResultId()                    for ra in result.getResultAlternatives():                        field_type = ra.getFieldType()                        tokens = ra.getTokens()                        summary = {"Result Id": result_id, "Tokens": [], "Field Type": None}                        for token in tokens:                            text = str(token.getText()).strip()                            st = token.getStartTime()                            et = token.getEndTime()                            timing = (st, et)                            command_id = token.getCommandId()                            if text:                                # print("Text: " + str(text))                                # print("Timing: " + str(timing))                                # print("Command id: " + str(command_id))                                # print("Field type: " + str(field_type))                                summary["Tokens"].append((text, timing))                                summary["Field Type"] = field_type                        ts = [t for t, timings in summary["Tokens"]]                        if ts:                            token_str = " ".join(ts)                            if summary["Field Type"] and cr.search(token_str):                                recognition_blocks.append(summary)        return recognition_blocks    def evaluate_commands(self, recognition_blocks):        state_dict = {"TIMEOUT": [], "PASSED": [], "DICTATION": []}        processed = -1        states = []        for position, summary in enumerate(recognition_blocks):            field_type = summary["Field Type"]            result_id = summary["Result Id"]            tokens = summary["Tokens"]            states.append((result_id, field_type, tokens))            # We reached a conclusion on the block            if summary["Field Type"] != "PARTIAL":                #states = sorted(states, key=lambda tup: tup[0])                if summary["Field Type"] == "DICTATION":                    # grammar failed, parsed to DICTATION, something happened that changed the context                    state_dict["DICTATION"].append(states)                elif summary["Field Type"] == "INCOMPLETE":                    # Grammar failed, final timeout                    state_dict["TIMEOUT"].append(states)                elif re.search(r'GRAMMAR', summary["Field Type"]):                    # Grammar was recognized correctly after len(recognition_blocks[position:p]) states                    state_dict["PASSED"].append(states)                states = []            for key, value in state_dict.items():                if value:                    print(str(key))                    border = "_" * len(str(key))                    print(border)                    for states in value:                        if states:                            for rid, ft, tokens in states:                                print("\t| " + str(ft) + ", " + str(rid) + "\t" + str(tokens))                #                # print("Slice summary: " + str(indices))                # if len(indices) > 1:                #     for summary in recognition_blocks[int(min(indices)): int(max(indices))]:                #         print("Summary, result ID: " + str(summary["Result Id"]) + "\t" + str(summary["Field Type"]) + ":\t" + str(                #         summary["Tokens"]))                # else:                #     index = indices[0]                #     if index - 1 >= 0:                #         print("Summary, result ID: " + str(recognition_blocks[index-1]["Result Id"]) + "\t" + str(                #             recognition_blocks[index - 1]["Field Type"]) + ":\t" + str(                #             recognition_blocks[index - 1]["Tokens"]))                #                #     print("Summary, result ID: " + str(block["Result Id"]) + "\t" + str(                #         block["Field Type"]) + ":\t" + str(                #         block["Tokens"]))                #                #     if index + 1 <= len(recognition_blocks ) - 1:                #         print("Summary, result ID: " + str(recognition_blocks[index + 1]["Result Id"]) + "\t" + str(                #             recognition_blocks[index + 1]["Field Type"]) + ":\t" + str(                #             recognition_blocks[index + 1]["Tokens"]))                #    def get_sessions_evaulated(self):        return self.islsdef get_session_logs_from_oid(author_oid, since, end_date):    """    Get session logs using OID and start/end dates    :param author_oid: Author OID    :param since: Start date    :param end_date: End date    :return: List of tuples (svc, channel, list of logs)    """    env = Env.get_env()    catalog = env.getCatalog()    channels = ['11025-hq']    sessions = []    channels = [CodedValueTools.construct(channel, "AudioQuality") for channel in channels]    for channel in channels:        for svc in catalog.listAllServicesBelow("InteractiveSessionLog", author_oid):            session_logs = Env.get_service("InteractiveSessionLog", svc).listSessionLogs(since, end_date, 255, 1, channel)            sessions += session_logs    return sessionsdef set_since(since, dateFormat):    if since == "yesterday":        cal = Calendar.getInstance()        cal.add(Calendar.DAY_OF_MONTH, -1)        cal.set(Calendar.HOUR_OF_DAY, 0)        cal.set(Calendar.MINUTE, 0)        cal.set(Calendar.SECOND, 0)        since = cal.getTime()    elif since[-5:] == "hours":        hoursN = int(since[:-5])        cal = Calendar.getInstance()        cal.add(Calendar.DAY_OF_MONTH, 0)        cal.set(Calendar.HOUR_OF_DAY, -hoursN)        cal.set(Calendar.MINUTE, 0)        cal.set(Calendar.SECOND, 0)        since = cal.getTime()    elif since[-4:] == "days":        daysN = int(since[:-4])        cal = Calendar.getInstance()        cal.add(Calendar.DAY_OF_MONTH, -daysN)        cal.set(Calendar.HOUR_OF_DAY, 0)        cal.set(Calendar.MINUTE, 0)        cal.set(Calendar.SECOND, 0)        since = cal.getTime()    elif since[-5:] == "weeks":        daysN = int(since[:-5]) * 7        cal = Calendar.getInstance()        cal.add(Calendar.DAY_OF_MONTH, -daysN)        cal.set(Calendar.HOUR_OF_DAY, 0)        cal.set(Calendar.MINUTE, 0)        cal.set(Calendar.SECOND, 0)        since = cal.getTime()    else:        sdf = SimpleDateFormat(dateFormat)        since = sdf.parse(since)    return sincedef set_endDate(endDate, dateFormat):    if endDate is None:        cal = Calendar.getInstance()        cal.add(Calendar.DAY_OF_MONTH, 0)        cal.add(Calendar.HOUR_OF_DAY, 0)        cal.add(Calendar.MINUTE, 0)        cal.add(Calendar.SECOND, 0)        endDate = cal.getTime()    else:        sdf = SimpleDateFormat(dateFormat)        endDate = sdf.parse(endDate)    return endDatedef get_arg_parser():    """    Build the argument parser    :return: Parser object    """    parser = argparse.ArgumentParser()    # Object Id arguments    parser.add_argument("-L", "--loglist", default=None, help="List containing the ISLs to evaluate")    parser.add_argument('-i', '--oid', help='object id under which to retrieve ISL services')    parser.add_argument('-z', '--root', default=[], action='append', help='root of object ids under which to retrieve ISL services')    parser.add_argument('-l', '--oidlist', help='A list of object ids under which to retrieve ISL services')    # Script specifics    parser.add_argument('-r', '--commandregex', default='.+', help='Regular expression related to the field types we want to match')    # Date formatting    parser.add_argument('-d', '--dateformat', default='MM-dd-yyyy', help='Format used for parsing "since" argument')    parser.add_argument('-s', '--since', help='Look for SessionLogs created after this date')    parser.add_argument('-e', '--endDate', help='Look for SessionLogs created up to this date')    return parserdef get_args():    """    Perform some input testing and initialize argument types    :return: Arg object containing formatted input arguments    """    parser = get_arg_parser()    args = get_arg_parser().parse_args()    if not (args.loglist or args.oid and args.since or args.root and args.since):        parser.error('must specify at least a list of sessions using --loglist <LOGFILE>')    if args.commandregex:        args.commandregex = re.compile(args.commandregex, re.IGNORECASE)        print("Field type regex compiled ~ \'" + str(args.commandregex.pattern) + "\'")    print(str(args))    return argsif __name__ == '__main__':    args = get_args()    Env.init()    # get OIDs    print("Getting author object IDs...")    oids = getOids(args.oid, args.oidlist, args.root)    # Get time frame    if args.since:        start_date = set_since(args.since, args.dateformat)    end_date = set_endDate(args.endDate, args.dateformat)    Env.init()    logs = []    # Get session OIDs from specified source    if args.loglist:        log_list_in = open(args.loglist, 'rb')        for position, oid in enumerate(log_list_in):            try:                session_log_id = ObjectIdTools.construct(str(oid).strip())                logs.append(session_log_id)            except Exception, e:                print("Error constructing session log object from oid: " + str(oid) + ", line: " + str(                    position) + ", file: " + str(log_list_in))    else:        for oid in oids:            # Get the logs the good ole fashion way            sessions = get_session_logs_from_oid(oid, start_date, end_date)            logs += sessions    rca = ReverseCommandArbiter()    log_count = len(logs)    cr = args.commandregex    for position, isl_str in enumerate(logs):        print("Evaluating log " + str(position) + "/" + str(log_count) + ": " + str(isl_str))        # Get recognition blocks        recognition_blocks = rca.get_recognition_blocks(isl_str, cr)        rca.evaluate_commands(recognition_blocks)    print(rca.get_sessions_evaulated())    # get session logs    # for each session log    #     get recognition blocks    #     for each block    #         evaluate block,v
"""    commandEvaluation.py    Created by Paul Hahn    08/28/17    Troubleshoot timeout causation in general and specific use cases."""# Environment imports# CDS and environment importsfrom base.env import Envfrom com.mmodal.cds import Environment, ObjectId, ObjectIdToolsfrom com.mmodal.cds.util import InternalObjectIdToolsfrom com.mmodal.cds.service.vocab import CodedValueTools# Utilitiesfrom utils.argutils import printArgs, getOidsfrom java.util import Date# Generalimport argparseimport refrom java.util import Calendarfrom java.text import SimpleDateFormat# Field typesfrom com.mmodal.cds.interactive import DictationFieldfrom com.mmodal.cds.interactive import GrammarFieldfrom com.mmodal.cds.interactive import TextSelectionFieldclass ReverseCommandArbiter(object):    """        A class to hold all of the functions specific to reverse engineering the command arbitration    """    def __init__(self):        # Blocks are what I am calling the recognition sequences ~ decoding loops        self.isls = []    def get_recognition_blocks(self, isl_str, cr):        """        A function to extract the field type, token, and timing metrics of an ISL and add it to our collection        :param isl_obj: ISL object        :return: recognition blocks related to this ISL        """        recognition_blocks = []        # Get Interactive Session Log and author specs        isl_svc = Env.get_service("InteractiveSessionLog", isl_str)        isl_obj = isl_svc.getSessionLog(isl_str)        author_oid_obj = ObjectIdTools.construct(isl_obj.getSpeakerId())        # Get call logs        print("Collecting recognition result alternatives..")        for call_log in isl_obj.getCallLogs():            if call_log and call_log.getResult():                for result in call_log.getResult().getResults():                    result_id = result.getResultId()                    for ra in result.getResultAlternatives():                        field_type = ra.getFieldType()                        tokens = ra.getTokens()                        summary = {"Result Id": result_id, "Tokens": [], "Field Type": None}                        for token in tokens:                            text = str(token.getText()).strip()                            st = token.getStartTime()                            et = token.getEndTime()                            timing = (st, et)                            command_id = token.getCommandId()                            if text:                                # print("Text: " + str(text))                                # print("Timing: " + str(timing))                                # print("Command id: " + str(command_id))                                # print("Field type: " + str(field_type))                                summary["Tokens"].append((text, timing))                                summary["Field Type"] = field_type                        ts = [t for t, timings in summary["Tokens"]]                        if ts:                            token_str = " ".join(ts)                            if summary["Field Type"] and cr.search(token_str):                                recognition_blocks.append(summary)        return recognition_blocks    def evaluate_commands(self, recognition_blocks):        state_dict = {"TIMEOUT": [], "PASSED": [], "DICTATION": []}        processed = -1        states = []        for position, summary in enumerate(recognition_blocks):            field_type = summary["Field Type"]            result_id = summary["Result Id"]            tokens = summary["Tokens"]            states.append((result_id, field_type, tokens))            # We reached a conclusion on the block            if summary["Field Type"] != "PARTIAL":                #states = sorted(states, key=lambda tup: tup[0])                if summary["Field Type"] == "DICTATION":                    # grammar failed, parsed to DICTATION, something happened that changed the context                    state_dict["DICTATION"].append(states)                elif summary["Field Type"] == "INCOMPLETE":                    # Grammar failed, final timeout                    state_dict["TIMEOUT"].append(states)                elif re.search(r'GRAMMAR', summary["Field Type"]):                    # Grammar was recognized correctly after len(recognition_blocks[position:p]) states                    state_dict["PASSED"].append(states)                states = []            for key, value in state_dict.items():                if value:                    print(str(key))                    border = "_" * len(str(key))                    print(border)                    for states in value:                        if states:                            for rid, ft, tokens in states:                                print("\t| " + str(ft) + ", " + str(rid) + "\t" + str(tokens))                #                # print("Slice summary: " + str(indices))                # if len(indices) > 1:                #     for summary in recognition_blocks[int(min(indices)): int(max(indices))]:                #         print("Summary, result ID: " + str(summary["Result Id"]) + "\t" + str(summary["Field Type"]) + ":\t" + str(                #         summary["Tokens"]))                # else:                #     index = indices[0]                #     if index - 1 >= 0:                #         print("Summary, result ID: " + str(recognition_blocks[index-1]["Result Id"]) + "\t" + str(                #             recognition_blocks[index - 1]["Field Type"]) + ":\t" + str(                #             recognition_blocks[index - 1]["Tokens"]))                #                #     print("Summary, result ID: " + str(block["Result Id"]) + "\t" + str(                #         block["Field Type"]) + ":\t" + str(                #         block["Tokens"]))                #                #     if index + 1 <= len(recognition_blocks ) - 1:                #         print("Summary, result ID: " + str(recognition_blocks[index + 1]["Result Id"]) + "\t" + str(                #             recognition_blocks[index + 1]["Field Type"]) + ":\t" + str(                #             recognition_blocks[index + 1]["Tokens"]))                #    def get_sessions_evaulated(self):        return self.islsdef get_session_logs_from_oid(author_oid, since, end_date):    """    Get session logs using OID and start/end dates    :param author_oid: Author OID    :param since: Start date    :param end_date: End date    :return: List of tuples (svc, channel, list of logs)    """    env = Env.get_env()    catalog = env.getCatalog()    channels = ['11025-hq']    sessions = []    channels = [CodedValueTools.construct(channel, "AudioQuality") for channel in channels]    for channel in channels:        for svc in catalog.listAllServicesBelow("InteractiveSessionLog", author_oid):            session_logs = Env.get_service("InteractiveSessionLog", svc).listSessionLogs(since, end_date, 255, 1, channel)            sessions += session_logs    return sessionsdef set_since(since, dateFormat):    if since == "yesterday":        cal = Calendar.getInstance()        cal.add(Calendar.DAY_OF_MONTH, -1)        cal.set(Calendar.HOUR_OF_DAY, 0)        cal.set(Calendar.MINUTE, 0)        cal.set(Calendar.SECOND, 0)        since = cal.getTime()    elif since[-5:] == "hours":        hoursN = int(since[:-5])        cal = Calendar.getInstance()        cal.add(Calendar.DAY_OF_MONTH, 0)        cal.set(Calendar.HOUR_OF_DAY, -hoursN)        cal.set(Calendar.MINUTE, 0)        cal.set(Calendar.SECOND, 0)        since = cal.getTime()    elif since[-4:] == "days":        daysN = int(since[:-4])        cal = Calendar.getInstance()        cal.add(Calendar.DAY_OF_MONTH, -daysN)        cal.set(Calendar.HOUR_OF_DAY, 0)        cal.set(Calendar.MINUTE, 0)        cal.set(Calendar.SECOND, 0)        since = cal.getTime()    elif since[-5:] == "weeks":        daysN = int(since[:-5]) * 7        cal = Calendar.getInstance()        cal.add(Calendar.DAY_OF_MONTH, -daysN)        cal.set(Calendar.HOUR_OF_DAY, 0)        cal.set(Calendar.MINUTE, 0)        cal.set(Calendar.SECOND, 0)        since = cal.getTime()    else:        sdf = SimpleDateFormat(dateFormat)        since = sdf.parse(since)    return sincedef set_endDate(endDate, dateFormat):    if endDate is None:        cal = Calendar.getInstance()        cal.add(Calendar.DAY_OF_MONTH, 0)        cal.add(Calendar.HOUR_OF_DAY, 0)        cal.add(Calendar.MINUTE, 0)        cal.add(Calendar.SECOND, 0)        endDate = cal.getTime()    else:        sdf = SimpleDateFormat(dateFormat)        endDate = sdf.parse(endDate)    return endDatedef get_arg_parser():    """    Build the argument parser    :return: Parser object    """    parser = argparse.ArgumentParser()    # Object Id arguments    parser.add_argument("-L", "--loglist", default=None, help="List containing the ISLs to evaluate")    parser.add_argument('-i', '--oid', help='object id under which to retrieve ISL services')    parser.add_argument('-z', '--root', default=[], action='append', help='root of object ids under which to retrieve ISL services')    parser.add_argument('-l', '--oidlist', help='A list of object ids under which to retrieve ISL services')    # Script specifics    parser.add_argument('-r', '--commandregex', default='.+', help='Regular expression related to the field types we want to match')    # Date formatting    parser.add_argument('-d', '--dateformat', default='MM-dd-yyyy', help='Format used for parsing "since" argument')    parser.add_argument('-s', '--since', help='Look for SessionLogs created after this date')    parser.add_argument('-e', '--endDate', help='Look for SessionLogs created up to this date')    return parserdef get_args():    """    Perform some input testing and initialize argument types    :return: Arg object containing formatted input arguments    """    parser = get_arg_parser()    args = get_arg_parser().parse_args()    if not (args.loglist or args.oid and args.since or args.root and args.since):        parser.error('must specify at least a list of sessions using --loglist <LOGFILE>')    if args.commandregex:        args.commandregex = re.compile(args.commandregex, re.IGNORECASE)        print("Field type regex compiled ~ \'" + str(args.commandregex.pattern) + "\'")    print(str(args))    return argsif __name__ == '__main__':    args = get_args()    Env.init()    # get OIDs    print("Getting author object IDs...")    oids = getOids(args.oid, args.oidlist, args.root)    # Get time frame    if args.since:        start_date = set_since(args.since, args.dateformat)    end_date = set_endDate(args.endDate, args.dateformat)    Env.init()    logs = []    # Get session OIDs from specified source    if args.loglist:        log_list_in = open(args.loglist, 'rb')        for position, oid in enumerate(log_list_in):            try:                session_log_id = ObjectIdTools.construct(str(oid).strip())                logs.append(session_log_id)            except Exception, e:                print("Error constructing session log object from oid: " + str(oid) + ", line: " + str(                    position) + ", file: " + str(log_list_in))    else:        for oid in oids:            # Get the logs the good ole fashion way            sessions = get_session_logs_from_oid(oid, start_date, end_date)            logs += sessions    rca = ReverseCommandArbiter()    log_count = len(logs)    cr = args.commandregex    for position, isl_str in enumerate(logs):        print("Evaluating log " + str(position) + "/" + str(log_count) + ": " + str(isl_str))        # Get recognition blocks        recognition_blocks = rca.get_recognition_blocks(isl_str, cr)        rca.evaluate_commands(recognition_blocks)    print(rca.get_sessions_evaulated())    # get session logs    # for each session log    #     get recognition blocks    #     for each block    #         evaluate block,V
" Fisa-vim-config" http://fisadev.github.io/fisa-vim-config/" version: 8.3.1" ============================================================================" Vim-plug initialization" Avoid modify this section, unless you are very sure of what you are doinglet vim_plug_just_installed = 0let vim_plug_path = expand('~/.vim/autoload/plug.vim')if !filereadable(vim_plug_path)    echo "Installing Vim-plug..."    echo ""    silent !mkdir -p ~/.vim/autoload    silent !curl -fLo ~/.vim/autoload/plug.vim --create-dirs https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim    let vim_plug_just_installed = 1endif" manually load vim-plug the first timeif vim_plug_just_installed    :execute 'source '.fnameescape(vim_plug_path)endif" Obscure hacks done, you can now modify the rest of the .vimrc as you wish :)" ============================================================================" Active plugins" You can disable or add new ones here:" this needs to be here, so vim-plug knows we are declaring the plugins we" want to usecall plug#begin('~/.vim/plugged')" Plugins from github repos:" Override configs by directory Plug 'arielrossanigo/dir-configs-override.vim'" Better file browserPlug 'scrooloose/nerdtree'" Code commenterPlug 'scrooloose/nerdcommenter'" Class/module browserPlug 'majutsushi/tagbar'" Code and files fuzzy finderPlug 'ctrlpvim/ctrlp.vim'" Extension to ctrlp, for fuzzy command finderPlug 'fisadev/vim-ctrlp-cmdpalette'" Zen codingPlug 'mattn/emmet-vim'" Git integrationPlug 'motemen/git-vim'" Tab list panelPlug 'kien/tabman.vim'" AirlinePlug 'vim-airline/vim-airline'Plug 'vim-airline/vim-airline-themes'" Terminal Vim with 256 colors colorschemePlug 'fisadev/fisa-vim-colorscheme'" Consoles as buffersPlug 'rosenfeld/conque-term'" Pending tasks listPlug 'fisadev/FixedTaskList.vim'" SurroundPlug 'tpope/vim-surround'" AutoclosePlug 'Townk/vim-autoclose'" Indent text objectPlug 'michaeljsmith/vim-indent-object'" Indentation based movementsPlug 'jeetsukumaran/vim-indentwise'" Python autocompletion, go to definition.Plug 'davidhalter/jedi-vim'" Better autocompletionPlug 'Shougo/neocomplcache.vim'" Snippets manager (SnipMate), dependencies, and snippets repoPlug 'MarcWeber/vim-addon-mw-utils'Plug 'tomtom/tlib_vim'Plug 'honza/vim-snippets'Plug 'garbas/vim-snipmate'" Git/mercurial/others diff icons on the side of the file linesPlug 'mhinz/vim-signify'" Automatically sort python importsPlug 'fisadev/vim-isort'" Drag visual blocks arroundPlug 'fisadev/dragvisuals.vim'" Window chooserPlug 't9md/vim-choosewin'" Python and other languages code checkerPlug 'scrooloose/syntastic'" Paint css colors with the real colorPlug 'lilydjwg/colorizer'" Ack code search (requires ack installed in the system)Plug 'mileszs/ack.vim'if has('python')    " YAPF formatter for Python    Plug 'pignacio/vim-yapf-format'endif" Relative numbering of lines (0 is the current line)" (disabled by default because is very intrusive and can't be easily toggled" on/off. When the plugin is present, will always activate the relative " numbering every time you go to normal mode. Author refuses to add a setting " to avoid that)" Plug 'myusuf3/numbers.vim'" Plugins from vim-scripts repos:" Search results counterPlug 'vim-scripts/IndexedSearch'" XML/HTML tags navigationPlug 'vim-scripts/matchit.zip'" Gvim colorschemePlug 'vim-scripts/Wombat'" Yank history navigationPlug 'vim-scripts/YankRing.vim'" Tell vim-plug we finished declaring plugins, so it can load themcall plug#end()" ============================================================================" Install plugins the first time vim runsif vim_plug_just_installed    echo "Installing Bundles, please ignore key map error messages"    :PlugInstallendif" ============================================================================" Vim settings and mappings" You can edit them as you wish" no vi-compatibleset nocompatible" allow plugins by file type (required for plugins!)filetype plugin onfiletype indent on" tabs and spaces handlingset expandtabset tabstop=4set softtabstop=4set shiftwidth=4" tab length exceptions on some file typesautocmd FileType html setlocal shiftwidth=4 tabstop=4 softtabstop=4autocmd FileType htmldjango setlocal shiftwidth=4 tabstop=4 softtabstop=4autocmd FileType javascript setlocal shiftwidth=4 tabstop=4 softtabstop=4" always show status barset ls=2" incremental searchset incsearch" highlighted search resultsset hlsearch" syntax highlight onsyntax on" show line numbersset nu" tab navigation mappingsmap tn :tabn<CR>map tp :tabp<CR>map tm :tabm map tt :tabnew map ts :tab split<CR>map <C-S-Right> :tabn<CR>imap <C-S-Right> <ESC>:tabn<CR>map <C-S-Left> :tabp<CR>imap <C-S-Left> <ESC>:tabp<CR>" navigate windows with meta+arrowsmap <M-Right> <c-w>lmap <M-Left> <c-w>hmap <M-Up> <c-w>kmap <M-Down> <c-w>jimap <M-Right> <ESC><c-w>limap <M-Left> <ESC><c-w>himap <M-Up> <ESC><c-w>kimap <M-Down> <ESC><c-w>j" old autocomplete keyboard shortcutimap <C-J> <C-X><C-O>" Comment this line to enable autocompletion preview window" (displays documentation related to the selected completion option)" Disabled by default because preview makes the window flickerset completeopt-=preview" save as sudoca w!! w !sudo tee "%"" simple recursive grepnmap ,r :Ack nmap ,wr :Ack <cword><CR>" use 256 colors when possibleif (&term =~? 'mlterm\|xterm\|xterm-256\|screen-256') || has('nvim')	let &t_Co = 256    colorscheme fisaelse    colorscheme delekendif" colors for gvimif has('gui_running')    colorscheme wombatendif" when scrolling, keep cursor 3 lines away from screen borderset scrolloff=3" autocompletion of files and commands behaves like shell" (complete only the common part, list the options that match)set wildmode=list:longest" better backup, swap and undos storageset directory=~/.vim/dirs/tmp     " directory to place swap files inset backup                        " make backup filesset backupdir=~/.vim/dirs/backups " where to put backup filesset undofile                      " persistent undos - undo after you re-open the fileset undodir=~/.vim/dirs/undosset viminfo+=n~/.vim/dirs/viminfo" store yankring history file there toolet g:yankring_history_dir = '~/.vim/dirs/'" create needed directories if they don't existif !isdirectory(&backupdir)    call mkdir(&backupdir, "p")endifif !isdirectory(&directory)    call mkdir(&directory, "p")endifif !isdirectory(&undodir)    call mkdir(&undodir, "p")endif" ============================================================================" Plugins settings and mappings" Edit them as you wish." Tagbar ----------------------------- " toggle tagbar displaymap <F4> :TagbarToggle<CR>" autofocus on tagbar openlet g:tagbar_autofocus = 1" NERDTree ----------------------------- " toggle nerdtree displaymap <F3> :NERDTreeToggle<CR>" open nerdtree with the current file selectednmap ,t :NERDTreeFind<CR>" don;t show these file typeslet NERDTreeIgnore = ['\.pyc$', '\.pyo$']" Tasklist ------------------------------" show pending tasks listmap <F2> :TaskList<CR>" CtrlP ------------------------------" file finder mappinglet g:ctrlp_map = ',e'" tags (symbols) in current file finder mappingnmap ,g :CtrlPBufTag<CR>" tags (symbols) in all files finder mappingnmap ,G :CtrlPBufTagAll<CR>" general code finder in all files mappingnmap ,f :CtrlPLine<CR>" recent files finder mappingnmap ,m :CtrlPMRUFiles<CR>" commands finder mappingnmap ,c :CtrlPCmdPalette<CR>" to be able to call CtrlP with default search textfunction! CtrlPWithSearchText(search_text, ctrlp_command_end)    execute ':CtrlP' . a:ctrlp_command_end    call feedkeys(a:search_text)endfunction" same as previous mappings, but calling with current word as default textnmap ,wg :call CtrlPWithSearchText(expand('<cword>'), 'BufTag')<CR>nmap ,wG :call CtrlPWithSearchText(expand('<cword>'), 'BufTagAll')<CR>nmap ,wf :call CtrlPWithSearchText(expand('<cword>'), 'Line')<CR>nmap ,we :call CtrlPWithSearchText(expand('<cword>'), '')<CR>nmap ,pe :call CtrlPWithSearchText(expand('<cfile>'), '')<CR>nmap ,wm :call CtrlPWithSearchText(expand('<cword>'), 'MRUFiles')<CR>nmap ,wc :call CtrlPWithSearchText(expand('<cword>'), 'CmdPalette')<CR>" don't change working directorylet g:ctrlp_working_path_mode = 0" ignore these files and folders on file finderlet g:ctrlp_custom_ignore = {  \ 'dir':  '\v[\/](\.git|\.hg|\.svn|node_modules)$',  \ 'file': '\.pyc$\|\.pyo$',  \ }" Syntastic ------------------------------" show list of errors and warnings on the current filenmap <leader>e :Errors<CR>" check also when just opened the filelet g:syntastic_check_on_open = 1" don't put icons on the sign column (it hides the vcs status icons of signify)let g:syntastic_enable_signs = 0" custom icons (enable them if you use a patched font, and enable the previous " setting)"let g:syntastic_error_symbol = '✗'"let g:syntastic_warning_symbol = '⚠'"let g:syntastic_style_error_symbol = '✗'"let g:syntastic_style_warning_symbol = '⚠'" Jedi-vim ------------------------------" All these mappings work only for python code:" Go to definitionlet g:jedi#goto_command = ',d'" Find ocurrenceslet g:jedi#usages_command = ',o'" Find assignmentslet g:jedi#goto_assignments_command = ',a'" Go to definition in new tabnmap ,D :tab split<CR>:call jedi#goto()<CR>" NeoComplCache ------------------------------" most of them not documented because I'm not sure how they work" (docs aren't good, had to do a lot of trial and error to make " it play nice)let g:neocomplcache_enable_at_startup = 1let g:neocomplcache_enable_ignore_case = 1let g:neocomplcache_enable_smart_case = 1let g:neocomplcache_enable_auto_select = 1let g:neocomplcache_enable_fuzzy_completion = 1let g:neocomplcache_enable_camel_case_completion = 1let g:neocomplcache_enable_underbar_completion = 1let g:neocomplcache_fuzzy_completion_start_length = 1let g:neocomplcache_auto_completion_start_length = 1let g:neocomplcache_manual_completion_start_length = 1let g:neocomplcache_min_keyword_length = 1let g:neocomplcache_min_syntax_length = 1" complete with workds from any opened filelet g:neocomplcache_same_filetype_lists = {}let g:neocomplcache_same_filetype_lists._ = '_'" TabMan ------------------------------" mappings to toggle display, and to focus on itlet g:tabman_toggle = 'tl'let g:tabman_focus  = 'tf'" Autoclose ------------------------------" Fix to let ESC work as espected with Autoclose pluginlet g:AutoClosePumvisible = {"ENTER": "\<C-Y>", "ESC": "\<ESC>"}" DragVisuals ------------------------------" mappings to move blocks in 4 directionsvmap <expr> <S-M-LEFT> DVB_Drag('left')vmap <expr> <S-M-RIGHT> DVB_Drag('right')vmap <expr> <S-M-DOWN> DVB_Drag('down')vmap <expr> <S-M-UP> DVB_Drag('up')" mapping to duplicate blockvmap <expr> D DVB_Duplicate()" Signify ------------------------------" this first setting decides in which order try to guess your current vcs" UPDATE it to reflect your preferences, it will speed up opening fileslet g:signify_vcs_list = [ 'git', 'hg' ]" mappings to jump to changed blocksnmap <leader>sn <plug>(signify-next-hunk)nmap <leader>sp <plug>(signify-prev-hunk)" nicer colorshighlight DiffAdd           cterm=bold ctermbg=none ctermfg=119highlight DiffDelete        cterm=bold ctermbg=none ctermfg=167highlight DiffChange        cterm=bold ctermbg=none ctermfg=227highlight SignifySignAdd    cterm=bold ctermbg=237  ctermfg=119highlight SignifySignDelete cterm=bold ctermbg=237  ctermfg=167highlight SignifySignChange cterm=bold ctermbg=237  ctermfg=227" Window Chooser ------------------------------" mappingnmap  -  <Plug>(choosewin)" show big letterslet g:choosewin_overlay_enable = 1" Airline ------------------------------let g:airline_powerline_fonts = 0let g:airline_theme = 'bubblegum'let g:airline#extensions#whitespace#enabled = 0" to use fancy symbols for airline, uncomment the following lines and use a" patched font (more info on the README.rst)"if !exists('g:airline_symbols')"   let g:airline_symbols = {}"endif"let g:airline_left_sep = '⮀'"let g:airline_left_alt_sep = '⮁'"let g:airline_right_sep = '⮂'"let g:airline_right_alt_sep = '⮃'"let g:airline_symbols.branch = '⭠'"let g:airline_symbols.readonly = '⭤'"let g:airline_symbols.linenr = '⭡',v
